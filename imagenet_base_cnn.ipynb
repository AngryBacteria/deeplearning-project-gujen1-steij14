{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cb6a8adaaaedb0",
   "metadata": {},
   "source": [
    "# Importierung\n",
    "\n",
    "Für die bessere Überischt importieren wir alles an einem Ort. Wir verwenden hier Keras V3. Damit wird ermöglicht, dass wir Backend-Agnostic arbeiten können. Das bedeutet, dass wir das Backend (Tensorflow, Pytorch, Jax) einfach wechseln können.\n",
    "Wir verwenden hier Pytorch als Backend, da es nativen GPU Support auf Windows hat. Ohne GPU geht das Training viel zu lange."
   ]
  },
  {
   "cell_type": "code",
   "id": "94aa4947907c5ff4",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "from keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import keras_tuner\n",
    "\n",
    "# Recommended to leave default values\n",
    "IMAGE_SIZE = (224, 224)\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "NUMBER_OF_CLASSES = 1  # 1 Because we use a binary classifier\n",
    "\n",
    "# Customizable values\n",
    "BATCH_SIZE = 64\n",
    "AUGMENT = True  # If the images should be augmented\n",
    "TUNE = False  # If the model architecture should be tuned"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eabbf0720028a6d3",
   "metadata": {},
   "source": [
    "# Hunde-Vögel Bild-Datensatz laden\n",
    "\n",
    "Mit der Funktion `image_dataset_from_directory` können wir die Bilddaten von der Festplatte laden. Dabei müssen sie in einem bestimmten Format sein. Ein Ordner mit jeweils einem Unterordner für jede Klasse. Hier werden auch direkt die Batches erstellt, die Bilder auf eine gemeinsame Grösse \"gepadded\" und ein Validation/Train Split erstellt. Die Labels sind für zwei Klassen Binär (0 oder 1) und bei mehreren Klassen als One-Hot-Encoded Vektor gespeichert.\n",
    "\n",
    "Für das initiale Training wird nur ein Datensatz mit Bildern von Hünden und Vögeln verwendet."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "_data_dir = os.path.join(\"data\", \"dog_bird\", \"images\")\n",
    "_entries = os.listdir(_data_dir)\n",
    "_folder_count = sum(os.path.isdir(os.path.join(_data_dir, entry)) for entry in _entries)\n",
    "\n",
    "TRAIN_DS, VAL_DS = keras.utils.image_dataset_from_directory(\n",
    "    _data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    shuffle=True,\n",
    "    interpolation=\"bilinear\",\n",
    "    pad_to_aspect_ratio=True,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "for _, _labels in TRAIN_DS.take(1):\n",
    "    print(_labels)\n",
    "    break\n",
    "\n",
    "for batch_images, _ in TRAIN_DS.take(1):\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(keras.utils.array_to_img(batch_images[i]))\n",
    "        plt.axis(\"off\")\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ded5bb0ffac76b0",
   "metadata": {},
   "source": [
    "# Basis-Architektur für CNN\n",
    "\n",
    "Dann bauen wir ein Basis-CNN. Der Kern sind 4 Gruppen an Layers, welche jeweils eine Convolution, Batch-Normalisierung, Max-Pooling und Dropout beinhalten. Dabei vergrössert sich die Filter-Grösse in jedem Schritt. Dadurch erhoffen wir uns zuerst kleinere Features zu finden und dann grössere Zusammenhänge in den Bildern abzudecken.\n",
    "\n",
    "Als Metriken verwenden wir die Precision, Recall, F1-Score und Accuracy. Die Loss-Funktion ist je nach Anzahl Klassen entweder BinaryCrossentropy oder CategoricalCrossentropy. Den Loss Berechnen wir jeweils direkt von den Logits, weil es sonst Probleme mit Pytorch gab. Es gab Probleme, wenn wir zuerst ein Klassifikationslayer verwendeten. Als Optimizer verwenden wir AdamW.\n",
    "\n",
    "# Data Augmentation\n",
    "\n",
    "Data Augmentation hilft dabei helfen die Klassifikation besser zu machen, indem die Daten variiert werden. Damit sollte das Modell weniger von Overfitting betroffen sein. Wir drehen sie, verändern den Kontrast und die Helligkeit."
   ]
  },
  {
   "cell_type": "code",
   "id": "fa973c311090a092",
   "metadata": {},
   "source": [
    "# TODO Transfer learning mit eigenem Modell (Nico)\n",
    "# TODO grosses modell\n",
    "# TODO Visualisierung der Daten (Jorma)\n",
    "# TODO Visualisierung der Validation (Nico)\n",
    "# TODO Bericht (Jorma)\n",
    "\n",
    "\n",
    "def build_cnn_model(\n",
    "    hp,\n",
    "    tune_inter_regularization=True,\n",
    "    tune_output_regularization=True,\n",
    "    tune_convolutions=False,\n",
    "    tune_lr=False,\n",
    "    tune_dens_layers=False,\n",
    "):\n",
    "\n",
    "    _METRICS = [\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "        keras.metrics.F1Score(name=\"f1\"),\n",
    "        (\n",
    "            keras.metrics.BinaryAccuracy(name=\"accuracy\")\n",
    "            if NUMBER_OF_CLASSES == 1\n",
    "            else keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Tuning setup\n",
    "    inter_dropout = (\n",
    "        hp.Boolean(\"inter_dropout\") if (TUNE and tune_inter_regularization) else False\n",
    "    )\n",
    "    inter_batch_norm = (\n",
    "        hp.Boolean(\"inter_batch_norm\") if (TUNE and tune_inter_regularization) else True\n",
    "    )\n",
    "\n",
    "    output_dropout = (\n",
    "        hp.Boolean(\"output_dropout\") if (TUNE and tune_output_regularization) else False\n",
    "    )\n",
    "    output_batch_norm = (\n",
    "        hp.Boolean(\"output_batch_norm\")\n",
    "        if (TUNE and tune_output_regularization)\n",
    "        else True\n",
    "    )\n",
    "\n",
    "    filter_size = (\n",
    "        hp.Choice(\"filter_size\", [8, 16, 32, 64]) if (TUNE and tune_convolutions) else 8\n",
    "    )\n",
    "    pool_type = (\n",
    "        hp.Choice(\"pool_type\", [\"max\", \"avg\"])\n",
    "        if (TUNE and tune_convolutions)\n",
    "        else \"max\"\n",
    "    )\n",
    "\n",
    "    learning_rate = (\n",
    "        hp.Choice(\"learning_rate\", [0.001, 0.0001, 0.00001])\n",
    "        if (TUNE and tune_lr)\n",
    "        else 0.001\n",
    "    )\n",
    "\n",
    "    dense_layer_amount = (\n",
    "        hp.Choice(\"dense_layer_amount\", [1, 2, 3]) if (TUNE and tune_dens_layers) else 3\n",
    "    )\n",
    "    dense_layer_base = (\n",
    "        hp.Choice(\"dense_layer_base\", [64, 128, 256])\n",
    "        if (TUNE and tune_dens_layers)\n",
    "        else 64\n",
    "    )\n",
    "\n",
    "    # Input layers\n",
    "    _keras_model = keras.Sequential()\n",
    "    _keras_model.add(layers.InputLayer(shape=INPUT_SHAPE, name=\"input\"))\n",
    "    if AUGMENT:\n",
    "        _keras_model.add(layers.RandomContrast(0.4))\n",
    "        _keras_model.add(layers.RandomBrightness(0.4))\n",
    "        # _keras_model.add(layers.RandomRotation(0.4))  ignored because performance was bad\n",
    "\n",
    "    _keras_model.add(layers.Rescaling(1.0 / 255))\n",
    "\n",
    "    # Intermediate architecture\n",
    "    for size in [filter_size, filter_size * 2, filter_size * 4, filter_size * 8]:\n",
    "        _keras_model.add(\n",
    "            layers.Conv2D(\n",
    "                size, kernel_size=(3, 3), activation=\"relu\", name=f\"conv_{size}\"\n",
    "            )\n",
    "        )\n",
    "        if inter_batch_norm:\n",
    "            _keras_model.add(layers.BatchNormalization(name=f\"batch_norm_{size}\"))\n",
    "        if pool_type == \"max\":\n",
    "            _keras_model.add(\n",
    "                layers.MaxPooling2D(pool_size=(2, 2), name=f\"max_pool_{size}\")\n",
    "            )\n",
    "        else:\n",
    "            _keras_model.add(\n",
    "                layers.AveragePooling2D(pool_size=(2, 2), name=f\"avg_pool_{size}\")\n",
    "            )\n",
    "        if inter_dropout:\n",
    "            _keras_model.add(layers.Dropout(0.2, name=f\"dropout_{size}\"))\n",
    "\n",
    "    # Final layers\n",
    "    if pool_type == \"max\":\n",
    "        _keras_model.add(layers.GlobalMaxPooling2D(name=\"global_max_pool\"))\n",
    "    else:\n",
    "        _keras_model.add(layers.GlobalAveragePooling2D(name=\"global_avg_pool\"))\n",
    "        \n",
    "    _keras_model.add(layers.Flatten(name=\"flatten\"))\n",
    "\n",
    "    if dense_layer_amount == 1:\n",
    "        _keras_model.add(\n",
    "            layers.Dense(dense_layer_base, activation=\"relu\", name=\"dense_1\")\n",
    "        )\n",
    "    elif dense_layer_amount == 2:\n",
    "        _keras_model.add(\n",
    "            layers.Dense(dense_layer_base, activation=\"relu\", name=\"dense_1\")\n",
    "        )\n",
    "        _keras_model.add(\n",
    "            layers.Dense(dense_layer_base * 2, activation=\"relu\", name=\"dense_2\")\n",
    "        )\n",
    "    elif dense_layer_amount == 3:\n",
    "        _keras_model.add(\n",
    "            layers.Dense(dense_layer_base, activation=\"relu\", name=\"dense_1\")\n",
    "        )\n",
    "        _keras_model.add(\n",
    "            layers.Dense(dense_layer_base * 2, activation=\"relu\", name=\"dense_2\")\n",
    "        )\n",
    "        _keras_model.add(\n",
    "            layers.Dense(dense_layer_base * 4, activation=\"relu\", name=\"dense_3\")\n",
    "        )\n",
    "\n",
    "    if output_batch_norm:\n",
    "        _keras_model.add(layers.BatchNormalization(name=\"batch_norm__keras_model\"))\n",
    "    if output_dropout:\n",
    "        _keras_model.add(layers.Dropout(0.2))\n",
    "    _keras_model.add(\n",
    "        layers.Dense(NUMBER_OF_CLASSES, activation=None, name=\"dense__keras_model\")\n",
    "    )\n",
    "\n",
    "    # Compile\n",
    "    _keras_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=_METRICS,\n",
    "    )\n",
    "    return _keras_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tuning\n",
    "Die gewählte Basis-Architektur wurde anschliessend durch Tuning verbessert. Es wurden insgesamt 3 Tuning-Durchläufe umgesetzt:\n",
    "- Regularisierung: Dropout und Batch-Normalisierung wurden getunt.\n",
    "- Convolutions und Learning-Rate: Die Anzahl der Filter, der Pooling-Typ und die Learning-Rate wurden getunt.\n",
    "- Dense Layers: Die Anzahl und Grösse der Dense Layers wurde getunt.\n",
    "\n",
    "# Training nach Tuning der Basis-Architektur\n",
    "\n",
    "Das Modell wird über mehrere Wochen hinweg trainiert. Dabei verwenden wir mehrere Techniken:\n",
    "- Early Stopping: Wenn die Validation Accuracy nicht mehr steigt, wird das Training abgebrochen. Damit verhindern wir ein Overfitting auch die Trainingsdaten.\n",
    "- Model Checkpointing: Das beste Modell wird gespeichert jeder Epoche gespeichert. Praktisch, wenn das Training abgebrochen wird.\n",
    "- Learning Rate Scheduler: Die Learning Rate wird reduziert, wenn die Validation Accuracy nicht mehr steigt.\n",
    "\n"
   ],
   "id": "83da2c3a4e0da917"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if TUNE:\n",
    "    tuner = keras_tuner.RandomSearch(\n",
    "        hypermodel=build_cnn_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_trials=20,\n",
    "        overwrite=False,\n",
    "        directory=\"tuning\",\n",
    "        project_name=\"tuning\",\n",
    "    )\n",
    "    tuner.search_space_summary()\n",
    "    tuner.search(TRAIN_DS, epochs=4, validation_data=VAL_DS)\n",
    "    base_model = tuner.get_best_models(num_models=1)[0]\n",
    "    tuner.results_summary(num_trials=5)\n",
    "    base_model.summary()\n",
    "    try:\n",
    "        keras.utils.plot_model(base_model, show_shapes=True)\n",
    "    except Exception as e:\n",
    "        print(\"Could not plot model\", e)\n",
    "else:\n",
    "    base_model = build_cnn_model(None)\n",
    "    base_model.summary()\n",
    "    try:\n",
    "        keras.utils.plot_model(base_model, show_shapes=True)\n",
    "    except Exception as e:\n",
    "        print(\"Could not plot model\", e)\n",
    "\n",
    "\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(\n",
    "    min_delta=0.015,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    patience=8,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "checkpointing_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"bird_dog_classifier.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    save_freq=\"epoch\",\n",
    "    initial_value_threshold=None,\n",
    ")\n",
    "lr_cb = keras.callbacks.ReduceLROnPlateau(\n",
    "    min_delta=0.015,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    patience=6,\n",
    "    factor=0.5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "base_history = base_model.fit(\n",
    "    TRAIN_DS,\n",
    "    validation_data=VAL_DS,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop_cb, checkpointing_cb, lr_cb],\n",
    ")"
   ],
   "id": "c8b802a113254585",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "1ef9a6f30d2ed637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate([\"accuracy\", \"loss\", \"precision\", \"recall\"]):\n",
    "    ax[i].plot(base_history.history[metric])\n",
    "    ax[i].plot(base_history.history[\"val_\" + metric])\n",
    "    ax[i].set_title(f\"Model {metric}\")\n",
    "    ax[i].set_xlabel(\"Epoch\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])"
   ],
   "id": "970df9a6d36d8de9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modell verwenden",
   "id": "440f0a5dd679c6f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = keras.utils.load_img(\"data/dog_bird/images/bird/n01514668_3210.JPEG\")\n",
    "plt.imshow(img)\n",
    "\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = keras.ops.expand_dims(img_array, 0)  # makes a batch out of the one image\n",
    "\n",
    "predictions = base_model.predict(img_array)\n",
    "print(predictions)\n",
    "score = float(keras.ops.sigmoid(predictions[0][0]))\n",
    "print(f\"This image is {100 * (1 - score):.2f}% bird and {100 * score:.2f}% dog.\")"
   ],
   "id": "6735291a6e0fb7a9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test123",
   "language": "python",
   "name": "test123"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
